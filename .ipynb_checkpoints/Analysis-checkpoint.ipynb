{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5adb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "class DotDict(dict):     \n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"      \n",
    "    def __getattr__(*args):         \n",
    "        val = dict.get(*args)        \n",
    "        return DotDict(val) if type(val) is dict else val              \n",
    "    __setattr__ = dict.__setitem__     \n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "\n",
    "with open(\"./config/config.yaml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "config = DotDict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f200dc3",
   "metadata": {},
   "source": [
    "## Comparison num_expressions in RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [str(i) for i in range(1, 6)]\n",
    "data = {}\n",
    "interesting_data = ['scores', 'max_scores']\n",
    "\n",
    "for num in nums:\n",
    "    a = torch.load('outputs/rl_'+num+'_000/model_200000.pt', map_location='cpu')\n",
    "    for col in interesting_data:\n",
    "        data[col] = data.get(col, []) + a[col]\n",
    "    data['num_expressions'] = data.get('num_expressions', []) + [num for _ in range(len(a['scores']))]\n",
    "    data['Episode'] = data.get('Episode', []) + [i*100 for i in range(1, len(a['scores']) + 1)]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Do a MA to see something\n",
    "window_size = 50\n",
    "for col in interesting_data:\n",
    "    df[col] = df.groupby('num_expressions')[col].transform(lambda s: s.rolling(window_size).mean())\n",
    "fig = px.line(df, x='Episode', y=\"scores\", color='num_expressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c89f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load('outputs/rl_3_000/model_200000.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'scores': a['scores']})\n",
    "df['scores'].rolling(10).mean().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e552d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 100\n",
      "/home/gridsan/amorenas/ETIN3/scripts/expression.py:88: RuntimeWarning: overflow encountered in exp\n",
      "  stack.append(function.function(first_operand))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32672619819641113\n"
     ]
    }
   ],
   "source": [
    "from scripts.dclasses import Dataset\n",
    "from scripts.language import Language\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "\n",
    "seed_everything(5)\n",
    "\n",
    "n_functions = 500\n",
    "import time\n",
    "language = Language(config.Language)\n",
    "ini = time.time()\n",
    "data = Dataset(n_functions, language)\n",
    "print(time.time() - ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73edc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "Xys = []\n",
    "\n",
    "for row in data:\n",
    "    X = torch.from_numpy(row['X'])\n",
    "    y = torch.from_numpy(row['y']).unsqueeze(1)\n",
    "    \n",
    "    Xys.append(torch.cat((X, y), dim=1))\n",
    "    \n",
    "Xys = torch.stack(Xys)\n",
    "\n",
    "torch.save(Xys, '../NeuralSymbolicRegressionThatScales-main/tensor2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "import time\n",
    "ini = time.time()\n",
    "for row in data:\n",
    "    a += len(row['Target Expression'].traversal)\n",
    "    \n",
    "a/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b65398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.expression import Expression\n",
    "from scripts.model import ETIN_model\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "HACER QUE TE CREE LA EXPRESIÓN DE OTRA MANERA:\n",
    "\n",
    "    . En cambio de coger un valor probabilísticamente, coger el máximo con cierta probabilidad\n",
    "      y con otra probabilidad coger un valor aleatorio del vector según probabilidades.\n",
    "\n",
    "'''\n",
    "\n",
    "# path = '/home/gridsan/amorenas/ETIN3/outputs/rl/model_80000.pt'\n",
    "path = None\n",
    "\n",
    "def nrmse(y_pred, y_true):\n",
    "    std_y = np.std(y_true)\n",
    "    nrmse = np.sqrt(np.mean((y_pred - y_true)**2)) / std_y\n",
    "    return nrmse, 5 / (1 + nrmse)\n",
    "\n",
    "if path is None:\n",
    "    etin_model = ETIN_model(config.Model, language.info_for_model)\n",
    "else:\n",
    "    etin_model = ETIN_model.load_from_checkpoint(path, cfg=config.Model, info_for_model=language.info_for_model)\n",
    "\n",
    "etin_model.to(device)\n",
    "errors = []\n",
    "rewards = []\n",
    "for i, row in enumerate(data):\n",
    "    new_expr = Expression(language, model=etin_model, prev_info=row)\n",
    "    if i == 5:\n",
    "        print(row['Target Expression'].to_sympy())\n",
    "        print(new_expr.to_sympy())\n",
    "        a = bbb\n",
    "    y_pred = new_expr.evaluate(row['X'])\n",
    "    if (np.isnan(y_pred).any() or np.abs(y_pred).max() > 1e5 or np.abs(y_pred).min() < 1e-2):\n",
    "        continue\n",
    "    error, reward = nrmse(y_pred, row['y'])\n",
    "    errors.append(error)\n",
    "    rewards.append(reward)\n",
    "\n",
    "print(np.mean(errors), np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f63413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data on commute times.\n",
    "rewards_series = pd.Series(rewards)\n",
    "\n",
    "rewards_series.plot.hist(grid=True, bins=20, rwidth=0.9,\n",
    "                         color='#607c8e')\n",
    "plt.title('Rewards for 500 equations')\n",
    "plt.xlabel('Counts')\n",
    "plt.ylabel('Rewards')\n",
    "plt.grid(axis='y', alpha=0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
